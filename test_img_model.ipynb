{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from dataset.polyvore import PolyvoreDataset\n",
    "from model.resnet import SiameseNetwork\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53306/53306 [00:01<00:00, 34968.47it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 35405.91it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 35093.82it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/abdelrahman/fashion-matching/fashion-compatibility/data/polyvore_outfits'\n",
    "# 1. Data Augmentation Transforms to be used in the Siamese Network model for creating positive samples\n",
    "augmented_img_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # Adjust size as needed\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "# For the creating the anchor and negative samples, use simpler transforms \n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img_train_dataset = PolyvoreDataset(data_dir=data_dir, dataset_type='train', img_transforms=img_transforms, augmented_img_transforms=augmented_img_transforms, target='image')\n",
    "img_val_dataset = PolyvoreDataset(data_dir=data_dir, dataset_type='valid', img_transforms=img_transforms, augmented_img_transforms=augmented_img_transforms, target='image')\n",
    "img_test_dataset = PolyvoreDataset(data_dir=data_dir, dataset_type='test', img_transforms=img_transforms, augmented_img_transforms=augmented_img_transforms, target='image')\n",
    "\n",
    "img_train_loader = DataLoader(img_train_dataset, batch_size=64, shuffle=True)\n",
    "img_val_loader = DataLoader(img_val_dataset, batch_size=64, shuffle=False)\n",
    "img_test_loader = DataLoader(img_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/anaconda3/envs/tts/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/abdelrahman/anaconda3/envs/tts/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 2. Siamese Network Architecture\n",
    "model = SiameseNetwork(model_name = 'resnet50', embedding_dim=128)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "anchor_pos_similarities = []\n",
    "anchor_neg_similarities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 680/680 [05:45<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in tqdm(img_test_loader, desc=\"Testing\"):\n",
    "        anchor, positive, negative = batch\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        output1, output2, output3 = model(anchor, positive, negative)\n",
    "        \n",
    "        # Calculate Similarities\n",
    "        for i in range(output1.size(0)):  # Iterate over batch items\n",
    "            anchor_pos_similarities.append(cosine_similarity(output1[i].unsqueeze(0).cpu(), output2[i].unsqueeze(0).cpu()).item())\n",
    "            anchor_neg_similarities.append(cosine_similarity(output1[i].unsqueeze(0).cpu(), output3[i].unsqueeze(0).cpu()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Similarity between Anchor and Positive: 0.9995341735799049\n",
      "Average Similarity between Anchor and Negative: 0.9986789179909767\n"
     ]
    }
   ],
   "source": [
    "avg_anchor_pos_sim = np.mean(anchor_pos_similarities)\n",
    "avg_anchor_neg_sim = np.mean(anchor_neg_similarities)\n",
    "print(f\"Average Similarity between Anchor and Positive: {avg_anchor_pos_sim}\")\n",
    "print(f\"Average Similarity between Anchor and Negative: {avg_anchor_neg_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
